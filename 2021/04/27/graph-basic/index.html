<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/panda-apple.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/panda-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/panda-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="基础知识图的表示给定一张图（Graph），记为$G &#x3D; (V, E)$ 结点$v$的度（degree），记为$\operatorname{d} (v)$或$\operatorname{deg} (v)$，表示一个结点的邻居结点的数量">
<meta property="og:type" content="article">
<meta property="og:title" content="图网络初步">
<meta property="og:url" content="http://example.com/2021/04/27/graph-basic/index.html">
<meta property="og:site_name" content="时间溢出的地方">
<meta property="og:description" content="基础知识图的表示给定一张图（Graph），记为$G &#x3D; (V, E)$ 结点$v$的度（degree），记为$\operatorname{d} (v)$或$\operatorname{deg} (v)$，表示一个结点的邻居结点的数量">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/TimeOverflow/picgo-images/master/simple-graph.png">
<meta property="article:published_time" content="2021-04-27T07:47:39.000Z">
<meta property="article:modified_time" content="2021-04-27T07:50:29.201Z">
<meta property="article:author" content="TimeOverflow">
<meta property="article:tag" content="图网络">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/TimeOverflow/picgo-images/master/simple-graph.png">

<link rel="canonical" href="http://example.com/2021/04/27/graph-basic/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>图网络初步 | 时间溢出的地方</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">时间溢出的地方</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/TimeOverflow" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/04/27/graph-basic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="TimeOverflow">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="时间溢出的地方">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          图网络初步
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-04-27 15:47:39 / 修改时间：15:50:29" itemprop="dateCreated datePublished" datetime="2021-04-27T15:47:39+08:00">2021-04-27</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>9.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>8 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><h4 id="图的表示"><a href="#图的表示" class="headerlink" title="图的表示"></a>图的表示</h4><p>给定一张图（Graph），记为$G = (V, E)$</p>
<p>结点$v$的度（degree），记为$\operatorname{d} (v)$或$\operatorname{deg} (v)$，表示一个结点的邻居结点的数量</p>
<a id="more"></a>
<h4 id="几种矩阵"><a href="#几种矩阵" class="headerlink" title="几种矩阵"></a>几种矩阵</h4><ul>
<li><p>邻接矩阵（Adjacency matrix）：$G = (V, E)$有$n$个结点，邻接矩阵$A \in \mathbb{R}^{n \times n}$表示为：</p>
<script type="math/tex; mode=display">
A_{i j}=\left\{\begin{array}{ll}
1 & \text { if }\left\{v_{i}, v_{j}\right\} \in E \text { and } i \neq j \\
0 & \text { otherwise }
\end{array}\right.</script><p>邻接矩阵是<strong>实对称</strong>矩阵</p>
</li>
<li><p>度矩阵（Degree matrix）：$G = (V, E)$有$n$个结点，度矩阵$D \in \mathbb{R}^{n \times n}$表示为：</p>
<script type="math/tex; mode=display">
D_{ii} = \operatorname{d}(v_i)</script><p>$D$是对角矩阵</p>
</li>
<li><p>拉普拉斯矩阵（Laplacian matrix）：对于一个<strong>无向图</strong>$G = (V, E)$有$n$个结点，$L \in \mathbb{R}^{n \times n}$定义为：</p>
<script type="math/tex; mode=display">
L = D - A</script><p>细化到每个元素：</p>
<script type="math/tex; mode=display">
L_{i j}=\left\{\begin{array}{ll}
d\left(v_{i}\right) & \text { if } i=j \\
-1 & \text { if }\left\{v_{i}, v_{j}\right\} \in E \text { and } i \neq j \\
0 & \text { otherwise }
\end{array}\right.</script><p>显然，拉普拉斯矩阵也是<strong>实对称</strong>矩阵</p>
</li>
<li><p>对称归一化拉普拉斯矩阵（Symmetric normalized Laplacian matrix）：对Laplacian matrix做归一化：</p>
<script type="math/tex; mode=display">
\begin{aligned}
L^{s y m} &=D^{-\frac{1}{2}} L D^{-\frac{1}{2}} \\
&=I-D^{-\frac{1}{2}} A D^{-\frac{1}{2}}
\end{aligned}</script><p>其中的元素为：</p>
<script type="math/tex; mode=display">
L_{i j}^{s y m}=\left\{\begin{array}{ll}
1 & \text { if } i=j \text { and } d\left(v_{i}\right) \neq 0, \\
-\frac{1}{\sqrt{d\left(v_{i}\right) d\left(v_{j}\right)}} & \text { if }\left\{v_{i}, v_{j}\right\} \in E \text { and } i \neq j, \\
0 \quad & \text { otherwise. }
\end{array}\right.</script></li>
</ul>
<hr>
<p>举个例子:chestnut:</p>
<p><img src="https://raw.githubusercontent.com/TimeOverflow/picgo-images/master/simple-graph.png" alt="一个例子：无向图"></p>
<p>对于上面一张有5个结点的无向图，可以得到其邻接矩阵与度矩阵为：</p>
<script type="math/tex; mode=display">
A = \begin{bmatrix}
0 & 1 & 1 & 1 & 1 \\
1 & 0 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 & 1 \\
1 & 0 & 0 & 1 & 0
\end{bmatrix}, \quad 
D = \begin{bmatrix}
4 &   &   &   &  \\
  & 1 &   &   &  \\
  &   & 1 &   &  \\
  &   &   & 2 &  \\
  &   &   &   & 2
\end{bmatrix}</script><p>相应的Laplacian矩阵为：</p>
<script type="math/tex; mode=display">
L = D - A = 
\begin{bmatrix}
 4 & -1 & -1 & -1 & -1 \\
-1 &  1 &  0 &  0 &  0 \\
-1 &  0 &  1 &  0 &  0 \\
-1 &  0 &  0 &  2 & -1 \\
-1 &  0 &  0 & -1 &  2
\end{bmatrix}</script><p>计算Symmetric Normalized Laplacian matrix：</p>
<script type="math/tex; mode=display">
\begin{aligned}
L^{s y m} &= D^{-\frac{1}{2}} L D^{-\frac{1}{2}} \\
          &= 
            \begin{bmatrix}
                1/2 &   &   &   &  \\
                  & 1 &   &   &  \\
                  &   & 1 &   &  \\
                  &   &   & 1/\sqrt{2} &  \\
                  &   &   &   & 1/\sqrt{2}
            \end{bmatrix}
            \begin{bmatrix}
                 4 & -1 & -1 & -1 & -1 \\
                -1 &  1 &  0 &  0 &  0 \\
                -1 &  0 &  1 &  0 &  0 \\
                -1 &  0 &  0 &  2 & -1 \\
                -1 &  0 &  0 & -1 &  2
            \end{bmatrix}
            \begin{bmatrix}
                1/2 &   &   &   &  \\
                  & 1 &   &   &  \\
                  &   & 1 &   &  \\
                  &   &   & 1/\sqrt{2} &  \\
                  &   &   &   & 1/\sqrt{2}
            \end{bmatrix} \\
            &= 
            \begin{bmatrix}
                                   1  & -\frac{1}{2}  & -\frac{1}{2}  & -\frac{1}{2\sqrt{2}}  & -\frac{1}{2\sqrt{2}} \\
                        -\frac{1}{2}  &            1  &            0  &                    0  &                    0 \\
                        -\frac{1}{2}  &            0  &            1  &                    0  &                    0 \\
                -\frac{1}{2\sqrt{2}}  &            0  &            0  &                    1  &         -\frac{1}{2} \\
                -\frac{1}{2\sqrt{2}}  &            0  &            0  &         -\frac{1}{2}  &                    1
            \end{bmatrix}        
\end{aligned}</script><hr>
<h3 id="图卷积的谱方法（Spectral-Method）"><a href="#图卷积的谱方法（Spectral-Method）" class="headerlink" title="图卷积的谱方法（Spectral Method）"></a>图卷积的谱方法（Spectral Method）</h3><h4 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="傅里叶变换"></a>傅里叶变换</h4><p>卷积和傅里叶变换有着密不可分的关系。在数学上，<strong>两个函数的卷积等于各自求傅里叶变换转成频域后乘积的逆傅里叶变换。</strong>傅里叶变换又可以通过谱图理论推广到Graph上进行变换。因此可以形成以下路线：</p>
<center>Convolution —— Fourier —— Spectral Graph</center>

<p>信号领域的傅里叶变换，简而言之就是构造频域内的一组正交基，一个函数在频域内可以由这组正交基线性表示。每个基都有自己的频率，同时表示一个函数时会有相应的傅里叶系数（即正交函数的振幅），这个傅里叶系数就是线性组合时的系数。可以表示如下：</p>
<script type="math/tex; mode=display">
f(x)=\sum_{k} F(k) e^{i k x}=\sum_{k} \underbrace{\frac{1}{2 \pi} \int_{-\infty}^{\infty} f\left(x^{\prime}\right) e^{-i k x^{\prime}} d x^{\prime}}_{\text {Fourier Coefficient }} e^{i k x}</script><p>其中$F(k)$是傅里叶系数，$e^{ikx}$是基函数，$k$是频率。</p>
<h4 id="图拉普拉斯算子"><a href="#图拉普拉斯算子" class="headerlink" title="图拉普拉斯算子"></a>图拉普拉斯算子</h4><p>为了将信息领域的傅里叶变换引申到图，即在图上做傅里叶变换，需要有对应的三种量：频率、正交基、傅里叶系数，如果在图处理时也能找到对应的这三个表示，就能把图信号转换到频域。为此，需要引入图拉普拉斯算子，即前面所说的拉普拉斯矩阵。将拉普拉斯矩阵做<strong>谱分解</strong>，得到特征值和相应的特征向量，特征值就对应于傅里叶变换中的频率，而特征向量就对应于这个频率下的基函数。</p>
<p>现假设一张图$G$的结点数目为$n$，则其拉普拉斯矩阵为$L \in \mathbb{R}^{n \times n}$，则$L$是一个<strong>半正定实对称矩阵</strong>。</p>
<hr>
<p>对于任意给定的向量$\boldsymbol{x}$，拉普拉斯矩阵的二次型为：$\boldsymbol{x}^TL\boldsymbol{x} = \sum_{e_{ij} \in E}(x_i - x_j)^2 \geq 0$，所以拉普拉斯矩阵是一个半正定矩阵，其所有特征值都<strong>大于</strong>0。</p>
<hr>
<p><strong>半正定实对称矩阵</strong>有如下的性质：</p>
<ul>
<li><strong>对称矩阵</strong>一定有$n$个线性无关的特征向量（$n$是Graph节点数）</li>
<li><strong>半正定矩阵</strong>的特征值一定非负</li>
<li><strong>对阵矩阵</strong>的特征向量相互正交，即所有特征向量构成的矩阵为正交矩阵</li>
</ul>
<p>对$L$矩阵做谱分解，可以得到：</p>
<script type="math/tex; mode=display">
L = U \Lambda U^T =
\begin{bmatrix}
\boldsymbol{\alpha}_1 & \boldsymbol{\alpha}_2 & \cdots & \boldsymbol{\alpha}_n
\end{bmatrix}
\begin{bmatrix}
\lambda_1 &           &        &           \\
          & \lambda_2 &        &           \\
          &           & \ddots &           \\
          &           &        & \lambda_n \\
\end{bmatrix}
\begin{bmatrix}
\boldsymbol{\alpha}_1^T \\ 
\boldsymbol{\alpha}_2^T \\ 
\vdots \\ 
\boldsymbol{\alpha}_n^T
\end{bmatrix}</script><p>其中，$U \in \mathbb{R}^{n \times n}$是一个正交矩阵，满足$UU^T=I$。$U = \begin{bmatrix}<br>\boldsymbol{\alpha}_1 &amp; \boldsymbol{\alpha}_2 &amp; \cdots &amp; \boldsymbol{\alpha}_n<br>\end{bmatrix}$表示$L$的$n$个特征向量，并且这些向量是<strong>线性无关的单位向量</strong>，$\boldsymbol{\alpha}_i \in \mathbb{R}^{n \times 1}$是列向量。$\lambda_k$是第$k$个特征向量对应的特征值，我们对特征值进行升序排列，即$\lambda_1 \le \lambda_2 \le \cdots \le \lambda_n$。</p>
<p>现在可以对比一下传统信号的傅里叶变换与图上的傅里叶变换：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>传统傅里叶变换</th>
<th>图傅里叶变换</th>
</tr>
</thead>
<tbody>
<tr>
<td>频率</td>
<td>特征值</td>
</tr>
<tr>
<td>基函数</td>
<td>特征向量</td>
</tr>
<tr>
<td>傅里叶系数</td>
<td>傅里叶系数</td>
</tr>
</tbody>
</table>
</div>
<p>现在只需要知道傅里叶系数如何计算，就可以得到完整的图傅里叶变换了。</p>
<p>假设一个有$n$个结点的图，其图上的信号用$\boldsymbol{x} = [x_1, x_2, \cdots, x_n]^T$来表示，其中$x_i$表示第$i$个结点上的信号强度，即图上每个结点的特征暂时都用一个标量来表示。定义<strong>图傅里叶变换</strong>为：</p>
<script type="math/tex; mode=display">
\boldsymbol{\tilde{x}} = U^T \boldsymbol{x}</script><p>$\boldsymbol{\tilde{x}} = [\tilde{x}_1, \tilde{x}_2, \cdots, \tilde{x}_n]$是信号$\boldsymbol{x}$经傅里叶变换后的表示，$\tilde{x}_i$是$\boldsymbol{x}$在第$i$个特征向量上的傅里叶系数，$\tilde{x}_i = &lt;\boldsymbol{\alpha}_i, \boldsymbol{x}&gt; = \boldsymbol{\alpha}_i^T \boldsymbol{x}$。这样就把图傅里叶变换与传统信号的傅里叶变换对应起来了。</p>
<p>同样可以定义<strong>图逆傅里叶变换</strong>：</p>
<p>由于$U$是一个正交矩阵，对$\boldsymbol{\tilde{x}} = U^T \boldsymbol{x}$左乘$U$，得$U\boldsymbol{\tilde{x}} = UU^T \boldsymbol{x} = \boldsymbol{x}$，即</p>
<script type="math/tex; mode=display">
\boldsymbol{x} = U \boldsymbol{\tilde{x}}</script><p>将上式展开成向量形式，如下：</p>
<script type="math/tex; mode=display">
\begin{align}
\boldsymbol{x} &= U \boldsymbol{\tilde{x}} = 
\begin{bmatrix}
\boldsymbol{\alpha}_1 & \boldsymbol{\alpha}_2 & \cdots & \boldsymbol{\alpha}_n
\end{bmatrix}
\begin{bmatrix}
\tilde{x}_1 \\ \tilde{x}_2 \\ \vdots \\ \tilde{x}_n
\end{bmatrix} \\
&= \tilde{x}_1 \boldsymbol{\alpha}_1 + \tilde{x}_2 \boldsymbol{\alpha}_2 + \cdots + \tilde{x}_n \boldsymbol{\alpha}_n \\
&= \sum_{i=1}^{n}\tilde{x}_i \boldsymbol{\alpha}_i
\end{align}</script><p>由此可以看出，图信号可以表示为拉普拉斯矩阵的特征向量的线性组合，这一点与传统傅里叶变换的思想也是一致的。</p>
<h4 id="番外：图拉普拉斯算子是如何定义的"><a href="#番外：图拉普拉斯算子是如何定义的" class="headerlink" title="番外：图拉普拉斯算子是如何定义的"></a>番外：图拉普拉斯算子是如何定义的</h4><p>一个很自然的想法是为什么定义拉普拉斯算子的人是怎么想到这个定义，以及这个定义和拉普拉斯有什么关系呢？首先需要看一下标准的拉普拉斯算子定义：</p>
<script type="math/tex; mode=display">
\Delta f=\sum_{i} \frac{\partial f}{\partial x^{2}}</script><p>即非混合二阶偏导数的和。$f$是拉普拉斯算子作用的「函数」，求函数各向二阶导数再求和，定义为$f$上的拉普拉斯算子。</p>
<p>图像作为一种离散数据（可以看做坐标的离散函数），拉普拉斯算子应该离散化。离散函数的一阶导数可以近似为一阶差分：</p>
<script type="math/tex; mode=display">
f^{\prime}(x)=\frac{\partial f(x)}{\partial x} \approx f(x+1)-f(x)</script><p>二阶导数近似于二阶差分：</p>
<script type="math/tex; mode=display">
\begin{aligned}
f^{\prime \prime}(x)=\frac{\partial^{2} f(x)}{\partial x^{2}} &=f^{\prime}(x)-f^{\prime}(x-1) \\
&=(f(x+1)-f(x))-(f(x)-f(x-1)) \\
&=f(x+1)+f(x-1)-2 f(x) \\
&=[f(x+1)-f(x)]+[f(x-1)-f(x)]
\end{aligned}</script><p><strong>某个二阶导数等于其在所有自由度上微扰之后获得的增益。</strong>一维函数其自由度可以理解为2，分别是+1方向和-1方向，增益分别为$f(x+1)-f(x)$和$f(x-1)-f(x)$，总增益为所有方向增益的和。</p>
<p>对于二维图像而言，</p>
<script type="math/tex; mode=display">
\begin{aligned}
(\Delta f)_{x, y} &=\frac{\partial f(x, y)}{\partial x^{2}}+\frac{\partial f(x, y)}{\partial y^{2}} \\
& \approx f(x+1, y)+f(x-1, y)-2 f(x, y) + f(x, y+1)+f(x, y-1)-2 f(x, y) \\
&       = [f(x+1, y)-f(x, y)]+[f(x-1, y)-f(x, y)] + [f(x, y+1)-f(x, y)]+[f(x, y-1)-f(x, y)]
\end{aligned}</script><p>上下左右共4个自由度$(1,0),(-1,0),(0,1),(0,-1)$，当然还可以任意的定义自由度，比如对角线也算的话，就是8个自由度。这样上式可以理解为：<strong>在图像上某一点，其拉普拉斯算子的值，即为对其进行扰动，使其变化到相邻像素后得到的增益。</strong></p>
<p>这给我们一种形象的结论：<strong>拉普拉斯算子就是在所有自由度上进行微小变化后获得的增益。</strong></p>
<p>那么推广到Graph，对于有$n$个节点的Graph，其邻接矩阵为$W$（这里把邻接矩阵记作$W$是考虑到加权图，对于无权图来说，$W=A$），这个Graph的自由度为$n$。因为如果该图是一个完全图，即任意两个节点之间都有一条边，那么对一个节点进行微扰，它可能变成任意一个节点。</p>
<p>那么对于图来说，上面的函数$f$就理所当然是一个$n$维的向量，即</p>
<script type="math/tex; mode=display">
\boldsymbol{f}=\left(f_{1}, \ldots, f_{N}\right)</script><p>其中，$\boldsymbol{f}_i$表示函数在结点$i$的值（这里的$\boldsymbol{f}$就是上一节中用来表示图的向量$\boldsymbol{x}$）。</p>
<p>对于任意结点$i$，对结点$i$进行微扰，它可能变为任意一个与之相邻的结点$j \in N_{i}$。</p>
<p>前面提到，拉普拉斯算子就是在所有自由度上进行微小变化后获得的增益。对于图而言，从结点$i$变化到结点$j$增益是$f_j - f_i$，不过通常这里经常写作写作取负数的形式（无非就是$L=D-W$还是$W-D$的问题），即$f_i - f_j$。再考虑边的权重，可以认为增益是$W_{ij}(f_i - f_j)$，那么对于结点$i$，总的增益即为拉普拉斯算子在结点$i$处的值：</p>
<script type="math/tex; mode=display">
\begin{aligned}
(\Delta \boldsymbol{f})_{i} &=\sum_{j} \frac{\partial f_{i}}{\partial j^{2}} \\
& \approx \sum_{j \in N_{i}} W_{i j}\left(f_{i}-f_{j}\right) \\
&=\sum_{j} W_{i j}\left(f_{i}-f_{j}\right) \\
&=\sum_{j} W_{i j} f_{i}-\sum_{j} W_{i j} f_{j} \\
&=(\boldsymbol{D} \boldsymbol{f})_{i}-(\boldsymbol{W} \boldsymbol{f})_{i} \\
&=[(\boldsymbol{D}-\boldsymbol{W}) \boldsymbol{f}]_{i}
\end{aligned}</script><p>上式中$j \in N_i$去掉是因为对于非邻接点$W_{ij} = 0$。</p>
<p>对于任意结点$i$， 都有上述的结论。故</p>
<script type="math/tex; mode=display">
\Delta \boldsymbol{f}=(\boldsymbol{D}-\boldsymbol{W}) \boldsymbol{f}</script><p>注意上式中$\Delta \boldsymbol{f}$要看作一个整体，表示<strong>图拉普拉斯算子作用在由图结点信息构成的向量上得到的结果</strong>。</p>
<p>对于无权图，$W$可以换成$A$，则拉普拉斯算子变为：</p>
<script type="math/tex; mode=display">
L = D - A</script><p>也就是拉普拉斯矩阵。</p>
<h4 id="图卷积"><a href="#图卷积" class="headerlink" title="图卷积"></a>图卷积</h4><p><strong>传统信号的卷积定理：</strong>函数卷积的傅里叶变换是函数傅立叶变换的乘积，即对于函数$f$与$h$，两者的卷积是其函数傅立叶变换乘积的逆变换，用公式表示即：</p>
<script type="math/tex; mode=display">
\boldsymbol{f} * \boldsymbol{h}=\mathcal{F}^{-1}[\hat{\boldsymbol{f}} \circ \hat{\boldsymbol{h}}]</script><p>类比到图信号上，$\boldsymbol{x} = [x_1, x_2, \cdots, x_n]^T$是图信号的表示，$\boldsymbol{h} = [h_1, h_2, \cdots, h_n]^T$是卷积核，我们可以将这两者都视为函数，则$\boldsymbol{x}$和$\boldsymbol{h}$的卷积可以按照以下步骤解出：</p>
<ol>
<li>计算$\boldsymbol{x}$的傅里叶变换$\boldsymbol{\tilde{x}} = U^T \boldsymbol{x}$</li>
<li>计算卷积核$\boldsymbol{h}$的傅里叶变换$\boldsymbol{\tilde{h}} = U^T \boldsymbol{h}$</li>
<li>求解$\boldsymbol{\tilde{x}}$和$\boldsymbol{\tilde{h}}$的element-wise乘积$\boldsymbol{\tilde{x}} \circ \boldsymbol{\tilde{h}}$，也等价与将$\boldsymbol{\tilde{h}}$组织为对角矩阵的形式$\operatorname{diag}(\boldsymbol{\tilde{h}})$，再计算其与$\boldsymbol{\tilde{x}}$的矩阵乘法，即$\operatorname{diag}(\boldsymbol{\tilde{h}}) \boldsymbol{\tilde{x}}$ </li>
<li>求上述结果的逆傅里叶变换，即左乘$U$</li>
</ol>
<p>总结一下，图上的卷积定义为：</p>
<script type="math/tex; mode=display">
(\boldsymbol{x} * \boldsymbol{h})_{\mathcal{G}}= U \operatorname{diag}(\boldsymbol{\tilde{h}}) U^{T} \boldsymbol{x}</script><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzUyNzcyNzE0Mg==&amp;mid=2247499330&amp;idx=1&amp;sn=57100c1e9eedf9d0d7bdce9d12dfa636&amp;chksm=fa79910bcd0e181dc33a69ccc8c898ad5fe156cb50024b7126ffc711f4e4b39287fc58c45c85&amp;mpshare=1&amp;scene=23&amp;srcid=0407O2gdPSAUp3bT2dvzpX02&amp;sharer_sharetime=1617727979936&amp;sharer_shareid=58b77e8351334912d4df0e7eb150704a#rd">入门必读 | 图卷积神经网络理论基础：从傅里叶变换到图卷积</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzU0ODk1MTcwNA==&amp;mid=2247484257&amp;idx=1&amp;sn=70ceb8cad8a091dd1c93aaca84b77d21&amp;chksm=fbb60096ccc18980ce324f5476d663d411f712765822635a20cb4c4f1ed209972ae5cbb54c6d&amp;token=350853886&amp;lang=zh_CN&amp;scene=21#wechat_redirect">图拉普拉斯算子为何定义为D-W</a></p>
<h3 id="深度学习中的图卷积"><a href="#深度学习中的图卷积" class="headerlink" title="深度学习中的图卷积"></a>深度学习中的图卷积</h3><p>深度学习中的Convolution就是要设计含有trainable共享参数的kernel，上面公式中的卷积核$\boldsymbol{h}$（及其傅里叶变换$\boldsymbol{\tilde{h}}$）是事先已经设定好的，如果将卷积核的傅里叶变换直接设为$\operatorname{diag}\left[\theta_{1}, \ldots, \theta_{n}\right]$作为参数进行学习，就可以得到初步的GCN<sup><a href="#fn_1" id="reffn_1">1</a></sup>：</p>
<script type="math/tex; mode=display">
\boldsymbol{y}_{\text {output }}=\sigma\left(U \boldsymbol{g}_{\theta} U^{T} \boldsymbol{x}\right)=\sigma\left(U \operatorname{diag}\left[\theta_{1}, \ldots, \theta_{n}\right] U^{T} \boldsymbol{x}\right)</script><p>上式中，$\boldsymbol{x}$就是graph上对应于每个结点的feature构成的向量$\boldsymbol{x} = [x_1, x_2, \cdots, x_n]^T$，目前仍然是每个结点信息是标量（即单通道），后续推广到向量很方便（多通道）。$\boldsymbol{y}_{\text {output }}$是该图卷积后的输出，所有的结点都要经过该操作，得到各自的输出。再$\sigma$激活后，传入下一层。$\boldsymbol{g}_{\boldsymbol{\theta}}=\operatorname{diag}\left[\theta_{1}, \ldots, \theta_{n}\right]$相当于拿这个卷积核每个节点卷一遍。</p>
<blockquote id="fn_1">
<sup>1</sup>. Bruna J, Zaremba W, Szlam A, et al. Spectral networks and locally connected networks on graphs[J]. arXiv preprint arXiv:1312.6203, 2013.<a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a>
</blockquote>
<h3 id="最初的图卷积网络（Graph-Convolution-Network）"><a href="#最初的图卷积网络（Graph-Convolution-Network）" class="headerlink" title="最初的图卷积网络（Graph Convolution Network）"></a>最初的图卷积网络（Graph Convolution Network）</h3><p><strong>GraphConv</strong>可以说是图卷积网络的开山之作。作者从谱卷积推导，给出的图卷积网络层的定义如下：</p>
<script type="math/tex; mode=display">
H^{(l+1)}=\sigma\left(\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} H^{(l)} W^{(l)}\right)</script><p>其中，$\tilde{A} = A + I$是加了自连接的无向图的邻接矩阵，相应地，$\tilde{D}_{ii} = \sum_{j}\tilde{A}_{ij}$，即$\tilde{D} = D + I$；$H^{(l)} \in \mathbb{R}^{N \times D}$是第$l$层的输出，$N$是图中结点的数量，$D$是结点的特征向量的长度，$H^{(0)} = X$；$W^{(l)} \in \mathbb{R}^{D \times F}$的第$l$层的权重，是网络中的可训练值；$\sigma(\cdot)$为激活函数。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%9B%BE%E7%BD%91%E7%BB%9C/" rel="tag"># 图网络</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/04/26/svm-1/" rel="prev" title="SVM1-线性可分支持向量机">
      <i class="fa fa-chevron-left"></i> SVM1-线性可分支持向量机
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="nav-number">1.</span> <span class="nav-text">基础知识</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E7%9A%84%E8%A1%A8%E7%A4%BA"><span class="nav-number">1.1.</span> <span class="nav-text">图的表示</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%87%A0%E7%A7%8D%E7%9F%A9%E9%98%B5"><span class="nav-number">1.2.</span> <span class="nav-text">几种矩阵</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%9A%84%E8%B0%B1%E6%96%B9%E6%B3%95%EF%BC%88Spectral-Method%EF%BC%89"><span class="nav-number">2.</span> <span class="nav-text">图卷积的谱方法（Spectral Method）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2"><span class="nav-number">2.1.</span> <span class="nav-text">傅里叶变换</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%AE%97%E5%AD%90"><span class="nav-number">2.2.</span> <span class="nav-text">图拉普拉斯算子</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%95%AA%E5%A4%96%EF%BC%9A%E5%9B%BE%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%AE%97%E5%AD%90%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9A%E4%B9%89%E7%9A%84"><span class="nav-number">2.3.</span> <span class="nav-text">番外：图拉普拉斯算子是如何定义的</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E5%8D%B7%E7%A7%AF"><span class="nav-number">2.4.</span> <span class="nav-text">图卷积</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">2.5.</span> <span class="nav-text">参考</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%9B%BE%E5%8D%B7%E7%A7%AF"><span class="nav-number">3.</span> <span class="nav-text">深度学习中的图卷积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%80%E5%88%9D%E7%9A%84%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%EF%BC%88Graph-Convolution-Network%EF%BC%89"><span class="nav-number">4.</span> <span class="nav-text">最初的图卷积网络（Graph Convolution Network）</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="TimeOverflow"
      src="/uploads/avatar.jpg">
  <p class="site-author-name" itemprop="name">TimeOverflow</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">8</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/TimeOverflow" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;TimeOverflow" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhangz1220@outlook.com" title="E-Mail → mailto:zhangz1220@outlook.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">TimeOverflow</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">33k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">30 分钟</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
